package org.apache.spark.sql.catalyst.expressions;
/**
 * The analyzer should be aware of Scala primitive types so as to make the
 * UDF return null if there is any null input value of these types. On the
 * other hand, Java UDFs can only have boxed types, thus this will return
 * Nil(has same effect with all false) and analyzer will skip null-handling
 * on them.
 */
public  class ScalaUDF extends org.apache.spark.sql.catalyst.expressions.Expression implements org.apache.spark.sql.catalyst.expressions.NonSQLExpression, org.apache.spark.sql.catalyst.expressions.UserDefinedExpression, scala.Product, scala.Serializable {
  static public abstract  R apply (T1 v1, T2 v2, T3 v3, T4 v4, T5 v5, T6 v6, T7 v7)  ;
  // not preceding
  public  java.lang.Object function ()  { throw new RuntimeException(); }
  public  org.apache.spark.sql.types.DataType dataType ()  { throw new RuntimeException(); }
  public  scala.collection.Seq<org.apache.spark.sql.catalyst.expressions.Expression> children ()  { throw new RuntimeException(); }
  public  scala.collection.Seq<scala.Option<org.apache.spark.sql.catalyst.encoders.ExpressionEncoder<?>>> inputEncoders ()  { throw new RuntimeException(); }
  public  scala.Option<java.lang.String> udfName ()  { throw new RuntimeException(); }
  public  boolean nullable ()  { throw new RuntimeException(); }
  public  boolean udfDeterministic ()  { throw new RuntimeException(); }
  // not preceding
  public   ScalaUDF (java.lang.Object function, org.apache.spark.sql.types.DataType dataType, scala.collection.Seq<org.apache.spark.sql.catalyst.expressions.Expression> children, scala.collection.Seq<scala.Option<org.apache.spark.sql.catalyst.encoders.ExpressionEncoder<?>>> inputEncoders, scala.Option<java.lang.String> udfName, boolean nullable, boolean udfDeterministic)  { throw new RuntimeException(); }
  // not preceding
  public  boolean deterministic ()  { throw new RuntimeException(); }
  public  java.lang.String toString ()  { throw new RuntimeException(); }
  /**
   * The analyzer should be aware of Scala primitive types so as to make the
   * UDF return null if there is any null input value of these types. On the
   * other hand, Java UDFs can only have boxed types, thus this will return
   * Nil(has same effect with all false) and analyzer will skip null-handling
   * on them.
   * @return (undocumented)
   */
  public  scala.collection.Seq<java.lang.Object> inputPrimitives ()  { throw new RuntimeException(); }
  /**
   * The expected input types of this UDF, used to perform type coercion. If we do
   * not want to perform coercion, simply use "Nil". Note that it would've been
   * better to use Option of Seq[DataType] so we can use "None" as the case for no
   * type coercion. However, that would require more refactoring of the codebase.
   * @return (undocumented)
   */
  public  scala.collection.Seq<org.apache.spark.sql.types.AbstractDataType> inputTypes ()  { throw new RuntimeException(); }
  /** This method has been generated by this script
   * <p>
   (1 to 22).map { x =&gt;
   val anys = (1 to x).map(x =&gt; "Any").reduce(_ + ", " + _)
   val childs = (0 to x - 1).map(x =&gt; s"val child$x = children($x)").reduce(_ + "\n  " + _)
   val converters = (0 to x - 1).map(x =&gt; s"lazy val converter$x = createToScalaConverter($x, child$x.dataType)").reduce(_ + "\n  " + _)
   val evals = (0 to x - 1).map(x =&gt; s"converter$x(child$x.eval(input))").reduce(_ + ",\n      " + _)
   * <p>
   s"""case $x =&gt;
   val func = function.asInstanceOf[($anys) =&gt; Any]
   $childs
   $converters
   (input: InternalRow) =&gt; {
   func(
   $evals)
   }
   """
   }.foreach(println)
   * <p>
   * @param ctx (undocumented)
   * @param ev (undocumented)
   * @return (undocumented)
   */
  public  org.apache.spark.sql.catalyst.expressions.codegen.ExprCode doGenCode (org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext ctx, org.apache.spark.sql.catalyst.expressions.codegen.ExprCode ev)  { throw new RuntimeException(); }
  // not preceding
  public  java.lang.String udfErrorMessage ()  { throw new RuntimeException(); }
  public  Object eval (org.apache.spark.sql.catalyst.InternalRow input)  { throw new RuntimeException(); }
}

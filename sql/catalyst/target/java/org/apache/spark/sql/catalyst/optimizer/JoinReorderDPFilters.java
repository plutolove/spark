package org.apache.spark.sql.catalyst.optimizer;
/**
 * Builds join graph information to be used by the filtering strategies.
 * Currently, it builds the sets of star/non-star joins.
 * It can be extended with the sets of connected/unconnected joins, which
 * can be used to filter Cartesian products.
 */
// not preceding
public  class JoinReorderDPFilters {
  // not preceding
  static public  scala.Option<org.apache.spark.sql.catalyst.optimizer.JoinGraphInfo> buildJoinGraphInfo (org.apache.spark.sql.internal.SQLConf conf, scala.collection.Seq<org.apache.spark.sql.catalyst.plans.logical.LogicalPlan> items, scala.collection.immutable.Set<org.apache.spark.sql.catalyst.expressions.Expression> conditions, scala.collection.Seq<scala.Tuple2<org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, java.lang.Object>> itemIndex)  { throw new RuntimeException(); }
  /**
   * Applies the star-join filter that eliminates join combinations among star
   * and non-star tables until the star join is built.
   * <p>
   * Given the oneSideJoinPlan/otherSideJoinPlan, which represent all the plan
   * permutations generated by the DP join enumeration, and the star/non-star plans,
   * the following plan combinations are allowed:
   * 1. (oneSideJoinPlan U otherSideJoinPlan) is a subset of star-join
   * 2. star-join is a subset of (oneSideJoinPlan U otherSideJoinPlan)
   * 3. (oneSideJoinPlan U otherSideJoinPlan) is a subset of non star-join
   * <p>
   * It assumes the sets are disjoint.
   * <p>
   * Example query graph:
   * <p>
   * t1   d1 - t2 - t3
   *  \  /
   *   f1
   *   |
   *   d2
   * <p>
   * star: {d1, f1, d2}
   * non-star: {t2, t1, t3}
   * <p>
   * level 0: (f1 ), (d2 ), (t3 ), (d1 ), (t1 ), (t2 )
   * level 1: {t3 t2 }, {f1 d2 }, {f1 d1 }
   * level 2: {d2 f1 d1 }
   * level 3: {t1 d1 f1 d2 }, {t2 d1 f1 d2 }
   * level 4: {d1 t2 f1 t1 d2 }, {d1 t3 t2 f1 d2 }
   * level 5: {d1 t3 t2 f1 t1 d2 }
   * <p>
   * @param oneSideJoinPlan One side of the join represented as a set of plan ids.
   * @param otherSideJoinPlan The other side of the join represented as a set of plan ids.
   * @param filters Star and non-star plans represented as sets of plan ids
   * @return (undocumented)
   */
  static public  boolean starJoinFilter (scala.collection.immutable.Set<java.lang.Object> oneSideJoinPlan, scala.collection.immutable.Set<java.lang.Object> otherSideJoinPlan, org.apache.spark.sql.catalyst.optimizer.JoinGraphInfo filters)  { throw new RuntimeException(); }
  static protected  scala.collection.Seq<org.apache.spark.sql.catalyst.expressions.Expression> splitConjunctivePredicates (org.apache.spark.sql.catalyst.expressions.Expression condition)  { throw new RuntimeException(); }
  static public  scala.Option<scala.Tuple2<org.apache.spark.sql.catalyst.expressions.Expression, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan>> findExpressionAndTrackLineageDown (org.apache.spark.sql.catalyst.expressions.Expression exp, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan plan)  { throw new RuntimeException(); }
  static protected  scala.collection.Seq<org.apache.spark.sql.catalyst.expressions.Expression> splitDisjunctivePredicates (org.apache.spark.sql.catalyst.expressions.Expression condition)  { throw new RuntimeException(); }
  static protected  org.apache.spark.sql.catalyst.expressions.Expression replaceAlias (org.apache.spark.sql.catalyst.expressions.Expression condition, org.apache.spark.sql.catalyst.expressions.AttributeMap<org.apache.spark.sql.catalyst.expressions.Expression> aliases)  { throw new RuntimeException(); }
  static protected  boolean canEvaluate (org.apache.spark.sql.catalyst.expressions.Expression expr, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan plan)  { throw new RuntimeException(); }
  static protected  boolean canEvaluateWithinJoin (org.apache.spark.sql.catalyst.expressions.Expression expr)  { throw new RuntimeException(); }
}

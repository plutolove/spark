[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/parquet/ParquetFileFormat.scala:127: value ENABLE_JOB_SUMMARY in class ParquetOutputFormat is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      && conf.get(ParquetOutputFormat.ENABLE_JOB_SUMMARY) == null) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/parquet/ParquetFileFormat.scala:261: class ParquetInputSplit in package hadoop is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m        new org.apache.parquet.hadoop.ParquetInputSplit([0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/parquet/ParquetFileFormat.scala:272: method readFooter in class ParquetFileReader is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m        ParquetFileReader.readFooter(sharedConf, filePath, SKIP_ROW_GROUPS).getFileMetaData[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/parquet/ParquetFileFormat.scala:450: method readFooter in class ParquetFileReader is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m          ParquetFileReader.readFooter([0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/v2.3/src/main/scala/org/apache/spark/sql/execution/datasources/orc/OrcShimUtils.scala:41: class DateWritable in package io is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    new DaysWritable(value.asInstanceOf[DateWritable]).gregorianDays[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/v2.3/src/main/scala/org/apache/spark/sql/execution/datasources/orc/OrcShimUtils.scala:49: class DateWritable in package io is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def getDateWritable(reuseObj: Boolean): (SpecializedGetters, Int) => DateWritable = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/UDFRegistration.scala:718: class UserDefinedAggregateFunction in package expressions is deprecated (since 3.0.0): Aggregator[IN, BUF, OUT] should now be registered as a UDF via the functions.udaf(agg) method.[0m
[0m[[33mwarn[0m] [0m      val udaf = clazz.getConstructor().newInstance().asInstanceOf[UserDefinedAggregateFunction][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/UDFRegistration.scala:719: method register in class UDFRegistration is deprecated (since 3.0.0): Aggregator[IN, BUF, OUT] should now be registered as a UDF via the functions.udaf(agg) method.[0m
[0m[[33mwarn[0m] [0m      register(name, udaf)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/parquet/ParquetPartitionReaderFactory.scala:122: class ParquetInputSplit in package hadoop is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m          LegacyBehaviorPolicy.Value) => RecordReader[Void, T]): RecordReader[Void, T] = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/parquet/ParquetPartitionReaderFactory.scala:127: class ParquetInputSplit in package hadoop is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      new org.apache.parquet.hadoop.ParquetInputSplit([0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/parquet/ParquetPartitionReaderFactory.scala:136: method readFooter in class ParquetFileReader is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      ParquetFileReader.readFooter(conf, filePath, SKIP_ROW_GROUPS).getFileMetaData[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/parquet/ParquetPartitionReaderFactory.scala:188: class ParquetInputSplit in package hadoop is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      split: ParquetInputSplit,[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/parquet/ParquetPartitionReaderFactory.scala:219: class ParquetInputSplit in package hadoop is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      split: ParquetInputSplit,[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DaysWritable.scala:41: class DateWritable in package io is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  extends DateWritable {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DaysWritable.scala:46: class DateWritable in package io is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def this(dateWritable: DateWritable) = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/sources/WriteToMicroBatchDataSource.scala:36: class WriteToDataSourceV2 in package v2 is deprecated (since 2.4.0): Use specific logical plans like AppendData instead[0m
[0m[[33mwarn[0m] [0m  def createPlan(batchId: Long): WriteToDataSourceV2 = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/sources/WriteToMicroBatchDataSource.scala:37: class WriteToDataSourceV2 in package v2 is deprecated (since 2.4.0): Use specific logical plans like AppendData instead[0m
[0m[[33mwarn[0m] [0m    WriteToDataSourceV2(new MicroBatchWrite(batchId, write), query)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/aggregate/udaf.scala:330: class UserDefinedAggregateFunction in package expressions is deprecated (since 3.0.0): Aggregator[IN, BUF, OUT] should now be registered as a UDF via the functions.udaf(agg) method.[0m
[0m[[33mwarn[0m] [0m    udaf: UserDefinedAggregateFunction,[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/aggregate/udaf.scala:330: class UserDefinedAggregateFunction in package expressions is deprecated (since 3.0.0): Aggregator[IN, BUF, OUT] should now be registered as a UDF via the functions.udaf(agg) method.[0m
[0m[[33mwarn[0m] [0m    udaf: UserDefinedAggregateFunction,[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/aggregate/udaf.scala:330: class UserDefinedAggregateFunction in package expressions is deprecated (since 3.0.0): Aggregator[IN, BUF, OUT] should now be registered as a UDF via the functions.udaf(agg) method.[0m
[0m[[33mwarn[0m] [0m    udaf: UserDefinedAggregateFunction,[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/aggregate/udaf.scala:330: class UserDefinedAggregateFunction in package expressions is deprecated (since 3.0.0): Aggregator[IN, BUF, OUT] should now be registered as a UDF via the functions.udaf(agg) method.[0m
[0m[[33mwarn[0m] [0m    udaf: UserDefinedAggregateFunction,[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/aggregate/udaf.scala:328: class UserDefinedAggregateFunction in package expressions is deprecated (since 3.0.0): Aggregator[IN, BUF, OUT] should now be registered as a UDF via the functions.udaf(agg) method.[0m
[0m[[33mwarn[0m] [0mcase class ScalaUDAF([0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/aggregate/udaf.scala:330: class UserDefinedAggregateFunction in package expressions is deprecated (since 3.0.0): Aggregator[IN, BUF, OUT] should now be registered as a UDF via the functions.udaf(agg) method.[0m
[0m[[33mwarn[0m] [0m    udaf: UserDefinedAggregateFunction,[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/aggregate/udaf.scala:328: class UserDefinedAggregateFunction in package expressions is deprecated (since 3.0.0): Aggregator[IN, BUF, OUT] should now be registered as a UDF via the functions.udaf(agg) method.[0m
[0m[[33mwarn[0m] [0mcase class ScalaUDAF([0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/meng/workspace/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/parquet/ParquetWriteBuilder.scala:90: value ENABLE_JOB_SUMMARY in class ParquetOutputFormat is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      && conf.get(ParquetOutputFormat.ENABLE_JOB_SUMMARY) == null) {[0m
[0m[[33mwarn[0m] [0m[0m

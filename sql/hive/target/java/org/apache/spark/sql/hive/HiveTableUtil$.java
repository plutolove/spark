package org.apache.spark.sql.hive;
/**
 * Creates a NewHadoopRDD based on the broadcasted HiveConf and other job properties that will be
 * applied locally on each slave.
 */
// not preceding
public  class HiveTableUtil$ {
  /**
   * Static reference to the singleton instance of this Scala object.
   */
  public static final HiveTableUtil$ MODULE$ = null;
  public   HiveTableUtil$ ()  { throw new RuntimeException(); }
  // not preceding
  public  void configureJobPropertiesForStorageHandler (org.apache.hadoop.hive.ql.plan.TableDesc tableDesc, org.apache.hadoop.conf.Configuration conf, boolean input)  { throw new RuntimeException(); }
}

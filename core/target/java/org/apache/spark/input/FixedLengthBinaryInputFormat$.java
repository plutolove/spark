package org.apache.spark.input;
/** Property name to set in Hadoop JobConfs for record length */
// not preceding
public  class FixedLengthBinaryInputFormat$ {
  /**
   * Static reference to the singleton instance of this Scala object.
   */
  public static final FixedLengthBinaryInputFormat$ MODULE$ = null;
  public   FixedLengthBinaryInputFormat$ ()  { throw new RuntimeException(); }
  // not preceding
  public  java.lang.String RECORD_LENGTH_PROPERTY ()  { throw new RuntimeException(); }
  /** Retrieves the record length property from a Hadoop configuration */
  public  int getRecordLength (org.apache.hadoop.mapreduce.JobContext context)  { throw new RuntimeException(); }
}
